{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4789e28d",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Time Series Forecasting Benchmark](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab57f3a",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Time Series Forecasting Benchmark](#toc1_)    \n",
    "  - [Data Setup](#toc1_1_)    \n",
    "    - [Holt-Winter Triple Exponential smoothing forecasting](#toc1_1_1_)    \n",
    "      - [Pre-requisites: Exponential Smoothing (ES)](#toc1_1_1_1_)    \n",
    "      - [History of Development](#toc1_1_1_2_)    \n",
    "        - [Damped Holt's double exponential smoothing](#toc1_1_1_2_1_)    \n",
    "    - [Gray Forecasting](#toc1_1_2_)    \n",
    "    - [Fuzzy Logic](#toc1_1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a42aebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "#setup system path for modular import\n",
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "#Processing and tests\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fetching stock data with the given name\n",
    "import yfinance as yf\n",
    "\n",
    "#for technical analysis\n",
    "import ta\n",
    "import mplfinance as mpf\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#Time series decomposition and forecasting prep\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf, kpss\n",
    "\n",
    "#Forecasting models\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt, ExponentialSmoothing # Holt-Winter\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df523604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.processing.denoising import Dimensional_Denoise\n",
    "from src.utils.processing.extract_stock_index import extract_index\n",
    "from src.utils.processing.feature_extraction import Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e3599",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Data Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cd31522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64.148095</td>\n",
       "      <td>64.801726</td>\n",
       "      <td>64.064291</td>\n",
       "      <td>64.583847</td>\n",
       "      <td>5036400</td>\n",
       "      <td>2013-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.516799</td>\n",
       "      <td>65.346413</td>\n",
       "      <td>63.997250</td>\n",
       "      <td>64.919037</td>\n",
       "      <td>3987000</td>\n",
       "      <td>2013-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.187206</td>\n",
       "      <td>65.379941</td>\n",
       "      <td>64.893911</td>\n",
       "      <td>65.103409</td>\n",
       "      <td>3431700</td>\n",
       "      <td>2013-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.977707</td>\n",
       "      <td>65.103407</td>\n",
       "      <td>63.134126</td>\n",
       "      <td>63.796139</td>\n",
       "      <td>7172600</td>\n",
       "      <td>2013-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.050340</td>\n",
       "      <td>63.527993</td>\n",
       "      <td>61.265424</td>\n",
       "      <td>62.120171</td>\n",
       "      <td>20268100</td>\n",
       "      <td>2013-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open       High        Low      Close    Volume        Date\n",
       "0  64.148095  64.801726  64.064291  64.583847   5036400  2013-01-02\n",
       "1  64.516799  65.346413  63.997250  64.919037   3987000  2013-01-03\n",
       "2  65.187206  65.379941  64.893911  65.103409   3431700  2013-01-04\n",
       "3  64.977707  65.103407  63.134126  63.796139   7172600  2013-01-07\n",
       "4  63.050340  63.527993  61.265424  62.120171  20268100  2013-01-08"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_index('BA') #Take Boeing for sample univariate dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0b0dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split training and testing classically\n",
    "\n",
    "train = df[df['Date'] < '2022-01-01']\n",
    "test = df[df['Date'] > '2022-01-01'] # Split 8 years train and 2 years test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3e7db",
   "metadata": {},
   "source": [
    "### AutoRegressive Integrated Moving Average (ARIMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470b878",
   "metadata": {},
   "source": [
    "#### Pre-requisites: The Moving Average (MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671040c3",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Holt-Winter Triple Exponential smoothing forecasting](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a78bc",
   "metadata": {},
   "source": [
    "#### <a id='toc1_1_1_1_'></a>[Pre-requisites: Exponential Smoothing (ES)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4711e5",
   "metadata": {},
   "source": [
    "Unlike Simple Moving Average (SMA), which treats the last n-datapoints evenly with the same weight = 1/n, the Exponential Moving Average (EMA) algorithm is a more refined version that emphasizes the recent data points more heavily, which makes it more sensitive to recent changes in price.\n",
    "\n",
    "While EMAs respond more quickly to recent data, they can produce false signal (which is the underlying problem of lag algorithms); however, they will be more effective when used alongside other technical indicators\n",
    "\n",
    "The General formula for EMA is\n",
    "\n",
    "$$EMA_t = (P_t.\\frac{S}{1 + d} + EMA_{t-1}.(1- \\frac{S}{1+d}))$$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $P_t$: Today's Price\n",
    "* S: Smoothing factor, the most common choice will be 2\n",
    "* d: Number of days in a moving window, shorter-period EMAs give more weight to recent prices than longer-period EMAs\n",
    "\n",
    "The Exponential Smoothing Technique work similarly to Exponential Moving Average in the behavior of putting large weight to more recent observations: \n",
    "\n",
    "$$y_t = \\alpha y_{t-1} + \\alpha(1-\\alpha) y_{t-2} + \\alpha(1- \\alpha^2) y_{t-3} + .....$$\n",
    "\n",
    "and as the observations come further to the past - the weights decrease exponentially with $0<\\alpha<1$ being the smoothing parameter\n",
    "\n",
    "Tuning the parameter $\\alpha$ gives larger weights to observations in distant past when $\\alpha$ is small (close to 0) and gives larger weights to recent observations when $\\alpha$ is large (close to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabac506",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "The Holt-Winters forecasting is one of the most popular forecasting techniques for time series, where it's used for purposes such as anomaly detection and capacity planning.\n",
    "\n",
    "The H-W forecasting model 3 aspects of the time series: \n",
    "\n",
    "* A typical value (average) or level of the series\n",
    "* A slope (trend) over time\n",
    "* A cyclical repeating pattern (seasonality) for example m = 4 for quarterly or m = 12 for monthly\n",
    "\n",
    "each of these has a distinct exponential smoothing series with a smoothing factor, as 3 smoothing factors are required for this approach, this is generally called the H-W Triple Exponentil Smoothing Formula  \n",
    "\n",
    "The H-W method uses exponential smoothing to encode lots of values from the past and use them to predict the \"typical\" value in the future. The model requires several parameters: one for each smoothing ($\\alpha, \\beta, \\gamma$), the length of the season, and the number of periods in the season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d363d2",
   "metadata": {},
   "source": [
    "#### <a id='toc1_1_1_2_'></a>[History of Development](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951be21",
   "metadata": {},
   "source": [
    "The model started by a Simple Exponential Smoothing technique to forecast the level (average) of the time series and didn't take into account trend or seasonality $$S_t = \\alpha Y_t + (1-\\alpha) S_{t-1}$$ and the Forecast for the next period (t+1) is the last calculated smoothed statistic $S_t$\n",
    "\n",
    "$$F_{t+1} = S_t$$\n",
    "\n",
    "Then Holt (1957) extended this baseline to allow the forecasting of data with a trend. \n",
    "\n",
    "Forecast equation: $$\\hat{y}_{t+h|t} = \\ell_t + hb_t$$\n",
    "\n",
    "Level equation: $$\\ell_t = \\alpha y_t + (1-\\alpha)(\\ell_{t-1} + b_{t-1})$$\n",
    "\n",
    "Trend equation: $$b_t = \\beta (\\ell_t - \\ell_{t-1}) + (1 - \\beta)b_{t-1}$$\n",
    "\n",
    "where:\n",
    "* l_t denotes and estimate of the level of the series at time t\n",
    "* b_t denotes and estimate of the trend (slope) of the series at time t\n",
    "* $\\alpha$ is the smoothing parameter for the level\n",
    "* $\\beta$ is the smoothing factor for the trend\n",
    "* h is the forecast horizon\n",
    "\n",
    "$$0< \\alpha, \\beta < 1$$\n",
    "\n",
    "This improvement allows the algorithm to capture the linear trend, work better with stable trend; however, for long horizon (large h), this can lead to unrealistic forecasts (too steep upward or downward)\n",
    "\n",
    "Therefore, to overcome the issue of long-term trend loss, Gardner & McKenzie (1985) introduced a damping parameter $\\theta$ that gradually reduces the trend contribution over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a5c47",
   "metadata": {},
   "source": [
    "##### <a id='toc1_1_1_2_1_'></a>[Damped Holt's double exponential smoothing](#toc0_)\n",
    "\n",
    "Level: $$\\ell_t = \\alpha y_t + (1-\\alpha)(\\ell_{t-1} + \\phi b_{t-1})$$\n",
    "\n",
    "Trend: $$b_t = \\beta(\\ell_t - \\ell_{t-1}) + (1-\\beta)\\phi b_{t-1}$$\n",
    "\n",
    "Forecast: $$\\hat{y}_{t+h} = \\ell_t + \\left( \\frac{1-\\phi^h}{1-\\phi} \\right)b_t, \\quad 0<\\phi<1$$\n",
    "\n",
    "* The damping parameter $\\phi$ shrinks the trend impact as h grows (longer forecast horizon)\n",
    "\n",
    "* If $\\phi = 1$ -> same as Holt's method (no damping)\n",
    "\n",
    "* If $\\phi = 0$ -> reduces to SES (no trend contribution)\n",
    "\n",
    "* If $\\phi$ stays between 0 and 1 -> the forecast flattens out at long horizons, which is more realistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8050f8ef",
   "metadata": {},
   "source": [
    "Winters later on extended this by adding one more seasonality exponential smoothing term with smoothing factor $\\gamma$, making the algorithm fit better with the time series \n",
    "\n",
    "The Holt-Winters Triple Exponential Smoothing (additive)\n",
    "\n",
    "* Level: $$\\ell_t = \\alpha (y_t - s_{t-m}) + (1-\\alpha)(\\ell_{t-1} + b_{t-1})$$\n",
    "$y_t - s_{t-m}$: current level value when excluding seasonal pattern, $\\ell_{t-1} + b_{t-1}$: the forecast from the previous timestep\n",
    "* Trend: $$b_t = \\beta (\\ell_t - \\ell_{t-1}) + (1-\\beta)b_{t-1}$$\n",
    "$\\ell_t - \\ell_{t-1}$: The observed slope in the level\n",
    "\n",
    "* Seasonality: $$s_t = \\gamma (y_t - \\ell_{t-1} - b_{t-1}) + (1-\\gamma)s_{t-m}$$\n",
    "\n",
    "* Forecast: $$\\hat{y}_{t+h} = \\ell_t + h b_t + s_{t+h-m}$$\n",
    "\n",
    "There's another approach in Holt-Winters, which is multiplicative, replacing \"+\" with \".\". The additive form is appropriate when the seasonal variation is roughly constant in magnitude, regardless of the level (average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simple Exponential Smoothing ---\n",
    "simple_model = ExponentialSmoothing(train['Close'], trend = 'mul', initialization_method = 'estimated', seasonal = 'mul', seasonal_periods = 7)\n",
    "simple_fit = simple_model.fit(smoothing_level=0.9, optimized=True)\n",
    "simple_forecast = simple_fit.forecast(len(test))\n",
    "\n",
    "# --- Holt-Winters Exponential Smoothing ---\n",
    "holt_model = ExponentialSmoothing(train, trend=\"add\", seasonal='add', damped_trend=False, seasonal_periods = 12) #when trend is used, we can all Double Exponential Smoothing, \n",
    "                                                                                                                # and when seasonal is also trigered, we can call it Triple\n",
    "holt_fit = holt_model.fit(smoothing_level=0.8, smoothing_trend=0.2) \n",
    "holt_forecast = holt_fit.forecast(len(test))\n",
    "\n",
    "# --- Damped Holt’s Forecasting ---\n",
    "dholt_model = ExponentialSmoothing(train, trend=\"add\", seasonal=None, damped_trend=True)\n",
    "dholt_fit = dholt_model.fit(smoothing_level=0.8, smoothing_trend=0.2, damping_trend=0.9)\n",
    "dholt_forecast = dholt_fit.forecast(len(test))\n",
    "\n",
    "# --- Holt’s Forecasting (statsmodels Holt) ---\n",
    "holt2_model = Holt(train, damped_trend=False)\n",
    "holt2_fit = holt2_model.fit(smoothing_level=0.8, smoothing_trend=0.2, optimized=True)\n",
    "holt2_forecast = holt2_fit.forecast(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84793f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.lineplot(x=train['Date'], y=train['Close'], label='Train', color='black')\n",
    "sns.lineplot(x=test['Date'], y=test['Close'], label='Test', color='orange')\n",
    "sns.lineplot(x=test['Date'], y=try_bc, label='Simple ES Forecast', color='red', linestyle='--')\n",
    "plt.title('Train, Test, and Simple ES Forecast')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Successfully capture the trend but not level and seasonality, will require improvement in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eaead0",
   "metadata": {},
   "source": [
    "When forecasting, add an error bands to show confidence level for future forecast by adding residual variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31219c",
   "metadata": {},
   "source": [
    "The Integration of Lasso and HHT in TS Forecasting\n",
    "\n",
    "After HHT, we get\n",
    "* A set of Hilbert transformed signals from IMFs\n",
    "* Instantaneous frequency\n",
    "* Instantaneous amplitude\n",
    "\n",
    "which introduces sparsity, which means not all components carry useful predictive information but rather just noise-dominated and redundant\n",
    "\n",
    "Lasso (L1 penalty) enforces sparsity by shrinking many coefficients exactly to 0 => perfect for HHT, as don't want all IMFs, just relevant ones. so Lasso will filters out noise features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335cca9",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_2_'></a>[Gray Forecasting](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f372e2",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_3_'></a>[Fuzzy Logic](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d7b8d5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
